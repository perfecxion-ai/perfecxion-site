---
title: '1.6Tb/s Photonic Interconnects: The Future of AI Infrastructure'
description: >-
  Deep dive into photonic ASICs and optical interconnects enabling 1.6Tb/s
  speeds for next-generation AI clusters.
date: '2025-08-18'
author: perfecXion AI Team
category: infrastructure
difficulty: advanced
readTime: 21 min read
tags:
  - photonics
  - optical-networking
  - high-speed-interconnects
  - AI-infrastructure
  - ASIC
---
# 1.6Tb/s Photonic Interconnects: The Future of AI Infrastructure

A Comparative Security Analysis of InfiniBand and Ethernet Fabrics for Sovereign AI and Regulated Workloads
Executive Summary
You need to understand the security trade-offs between InfiniBand and high-performance Ethernet (RoCEv2) before you build your sovereign AI infrastructure. These aren't minor differences. They're fundamental architectural choices that will shape your security posture for years.

InfiniBand runs everything through one brain—the Subnet Manager. Fast and efficient, yes. But that single control point creates a monolithic security domain where one compromise can unravel everything. Ethernet takes the opposite approach. It layers security controls from multiple vendors using open standards. More complex to manage? Absolutely. But when an attacker breaches one layer, others remain standing.

Here's what actually matters for your security architecture:

Authentication tells a different story for each fabric. InfiniBand uses hardware keys managed centrally—strong but brittle. Compromise the Subnet Manager and you own the kingdom. Ethernet spreads trust across the network with 802.1X port authentication and MACsec encryption. Harder to manage, but it follows zero-trust principles your auditors will recognize.

Tenant isolation reveals an even starker contrast. InfiniBand's P_Keys stop data from crossing boundaries—silicon-enforced, microsecond fast. But here's the problem: tenants can still map your entire network topology. They can't touch other tenants' data, but they know exactly where everyone lives. Ethernet's VXLAN completely blinds tenants to anything outside their virtual network. The catch? You're trusting software tunnel endpoints instead of hardware.

QoS mechanisms become weapons in the wrong hands. InfiniBand degrades gracefully under attack—slower but stable. RoCEv2's Priority Flow Control? That's a different beast. One malicious burst of traffic can trigger cascading pause frames that deadlock your entire fabric. We've seen this happen. The network doesn't slow down; it stops.

Telemetry integrity follows the same pattern. InfiniBand asks you to trust its black-box management stack—you get comprehensive data but can't verify how it's collected or secured. Ethernet hands you transparent protocols and says "secure it yourself." More work, but you control every aspect.

Your fabric choice isn't about speed benchmarks. It's about sovereignty, compliance, and resilience.

Ethernet wins on strategic grounds: multiple vendors prevent lock-in, open standards enable auditing, and metadata isolation keeps tenants truly separated. These aren't nice-to-haves for sovereign AI—they're requirements. But Ethernet demands expertise. Misconfigure PFC thresholds and watch your fabric collapse. Skip MACsec and leave your links exposed.

InfiniBand offers simplicity at a price: vendor dependence and opacity. One company controls your critical infrastructure. You can't audit what you can't see. Yet for teams lacking deep networking expertise, InfiniBand's integrated approach reduces operational risk.

The right choice? That depends on your threat model, your team's capabilities, and whether technological independence outweighs operational complexity in your risk calculus.

Section 1: Architectural Foundations and Their Security Implications
Architecture determines security. Always has, always will.

InfiniBand and Ethernet take opposite approaches to building high-performance AI fabrics. InfiniBand puts one entity in charge—the Subnet Manager runs everything like a software-defined network from day one. Ethernet? It stacks protocols developed over decades, each handling its own piece of the security puzzle.

This creates your fundamental trade-off. InfiniBand concentrates both power and risk in that central controller. One place to secure, one place to fail. Ethernet spreads control across layers—harder to manage, harder to break completely.

1.1. The InfiniBand Fabric: A Centrally Managed, Software-Defined Architecture
InfiniBand builds its fabric with point-to-point connections between every device. Switches, servers with Host Channel Adapters (HCAs)—they all connect directly. But here's what matters: the Subnet Manager controls everything.

The SM discovers your topology, assigns addresses (LIDs), programs routing tables, and enforces security. Think of it as SDN before SDN was cool. One brain, total control. Efficient? Incredibly. Single point of failure? You bet.

RDMA defines InfiniBand's greatest strength and weakness. Data moves directly between server memories, skipping CPUs and kernels entirely. Sub-microsecond latency becomes possible. Your firewalls, IDS, and packet sniffers? They see nothing. The traffic bypasses every traditional security tool you've deployed.

Because the SM holds all the cards, losing it means losing control. InfiniBand addresses this with standby SMs—multiple managers waiting to take over. They elect a master, maintain state, and use virtual IPs to ensure seamless failover. It works, but you're still betting everything on that election process staying secure.

1.2. The Converged Ethernet Fabric: A Layered, Standards-Based Architecture for RoCEv2
Ethernet wasn't built for AI workloads. It adapted. RoCEv2 wraps InfiniBand's transport layer in UDP/IP packets, bringing RDMA to standard networks. Now your AI traffic routes over the same Layer 3 infrastructure as everything else. Scale improves. Integration simplifies. But complexity explodes.

Why does this matter? RDMA can't tolerate packet loss. Drop one packet and performance craters. Standard Ethernet drops packets all the time—it's designed to.

So we engineer "lossless" Ethernet using Priority Flow Control and Explicit Congestion Notification. PFC sends pause frames when buffers fill, stopping upstream traffic cold. ECN marks packets before congestion hits, telling senders to slow down. Get these settings wrong—and most people do—and your fabric becomes unstable. Get them right and you have a house of cards that works until someone sneezes.

Modern RoCEv2 deployments run BGP-EVPN for their control plane. BGP distributes routing information. EVPN extensions handle MAC addresses and VXLAN overlays for multi-tenancy. Scalable? Yes. Standardized? Absolutely. Another layer of complexity to secure? You know the answer.

1.3. The Security Dichotomy: Kernel Bypass vs. the Network Stack
Here's where security models diverge completely. InfiniBand implements everything in hardware—transport, reliability, everything. No kernel involvement means no kernel vulnerabilities. Fast and secure against OS-level attacks.

But your security team can't see anything. Firewalls miss it. IDS misses it. Every monitoring tool you've invested in becomes useless for this traffic. You get InfiniBand's built-in security or nothing.

RoCEv2 sits in the middle. RDMA still bypasses the kernel for speed. But those are real IP packets moving through your network. Your switches can see them, filter them with ACLs, route them normally. The TCP stack stays out of it, but IP addressing still works. Some visibility returns, though the actual data path remains just as opaque to your host-based tools.

This drives fundamentally different security philosophies.

InfiniBand's security model: monolithic. Everything depends on the SM staying secure and correctly configured. Compromise it and an attacker can reroute traffic, remove partitions, own your fabric. One ring to rule them all.

Ethernet's model: defense in depth. 802.1X guards the ports. MACsec protects the links. VXLAN segments the network. Each layer operates independently. Breach one, the others keep fighting. That's zero-trust architecture—never assume any single control is enough.

Which is better? If you're defending against advanced threats, Ethernet's distributed model makes more sense. Yes, it's harder to manage. But when nation-states come knocking, you want multiple walls, not one really thick one.

Section 2: Authentication and Authorization: Establishing Trust in the Fabric
You can't secure what you can't authenticate. Both fabrics know this. They just implement it differently.

InfiniBand trusts from the center out—the SM validates itself to devices, then controls who talks to whom. Ethernet trusts nothing initially—every device proves itself at connection, every link gets secured independently.

2.1. InfiniBand's Centralized Trust Model: The Subnet Manager and Key-Based Authentication
InfiniBand's "keys" aren't cryptographic—they're passwords. Simple, shared secrets that control access. The SM holds them all, distributes them, enforces them.

The M_Key protects device configurations. SM assigns one to each port. Try to change a setting without the right M_Key? Packet dropped. The device might even alert the SM about your attempt. Smart implementations add lease periods (keys expire if the SM dies) and read protection (can't extract keys even with valid queries).

SM_Keys and allowed GUID lists stop rogue managers from hijacking your fabric. The SM_Key acts like a password for the election process—no key, no leadership. The allowed_sm_guids list goes further: only pre-approved GUIDs can even try to become master. Belt and suspenders for control plane security.

Every InfiniBand port carries a 64-bit GUID burned into silicon—like a MAC address you can't change. Spoofing becomes nearly impossible. Want more security? Configure your SM with a static topology map. Device shows up with the wrong GUID or right GUID in the wrong place? SM refuses to configure it. That device stays isolated, talking to no one.

2.2. Ethernet's Distributed Trust Model: 802.1X, MACsec, and Centralized Authentication Servers
Ethernet doesn't trust anything by default. It uses open standards, each handling its piece of the authentication puzzle. Central servers coordinate, but trust gets verified at every layer.

802.1X turns every switch port into a security checkpoint. Device plugs in? Port stays locked, blocking everything except authentication traffic. The switch becomes a middleman, passing credentials between the device and your RADIUS or TACACS+ server. Server says yes? Port opens. Server says no? That device stays locked out. No exceptions, no shortcuts.

MACsec protects what 802.1X can't—the actual wire. Point-to-point AES encryption, integrity checking, replay protection. Someone taps your fiber? They get encrypted garbage. Try to inject packets? MACsec spots the forgery. This stops physical attacks cold, whether on inter-switch links or server connections.

RADIUS and TACACS+ run the authentication backend. One database, all your credentials, feeding both 802.1X and admin logins. High-security shops prefer TACACS+—it encrypts everything in the AAA packet. RADIUS only encrypts passwords, leaving commands and responses exposed. Small difference, big implications when adversaries monitor your management traffic.

The authentication philosophies couldn't be more different. InfiniBand protects a pre-built fabric from internal threats—it assumes the fabric exists and needs protection. Ethernet assumes nothing. Every device gets challenged. Every link gets secured. Nothing connects without proof.

For regulated environments demanding auditable access control? Ethernet's explicit authentication at every entry point wins. Your auditors understand 802.1X. They can verify MACsec. InfiniBand's internal key system? Harder to explain, harder to audit.

Section 3: Tenant Isolation: A Comparative Analysis of Enforcement Mechanisms
Multi-tenant isolation isn't optional for sovereign AI. One tenant discovering another's existence? That's a compliance violation waiting to happen.

InfiniBand enforces isolation in hardware using partitions. Ethernet builds virtual networks on top of physical ones. Both work. Neither is perfect.

3.1. InfiniBand Partitions (P_Keys): Silicon-Enforced Segmentation
P_Keys are InfiniBand's answer to isolation. Each packet carries a 16-bit partition key. Hardware checks it against an allowed list. Wrong key? Packet dropped at wire speed, no CPU involved. The SM defines partitions, assigns keys, and that's it—silicon does the rest.

This is as fast as isolation gets. Microsecond decisions, zero performance penalty.

P_Keys offer more than binary access. Full members talk to everyone in the partition. Limited members only talk to full members, not each other. Perfect for hub-and-spoke designs: compute nodes (limited) access shared storage (full) but can't see neighboring compute nodes. One bit controls it all—elegant and effective.

But here's the dirty secret: InfiniBand leaks metadata everywhere. Run ibnetdiscover from any partition and you'll see the entire fabric—every GUID, every LID, every tenant's infrastructure laid bare. The data plane stays isolated, sure. But attackers get a complete network map for free. They can't touch other tenants' traffic, but they know exactly where everyone is. That's not isolation; that's a reconnaissance goldmine.

3.2. Ethernet Virtual Overlays (VXLAN/EVPN): Encapsulation-Based Segmentation
VXLAN solves multi-tenancy differently. Wrap each tenant's Layer 2 traffic in UDP packets, send it across your Layer 3 network. A 24-bit identifier gives you 16 million possible tenant networks—compare that to VLAN's measly 4,000. Each tenant sees only their virtual network. The physical topology? Completely hidden.

BGP-EVPN manages these virtual networks at scale. Instead of flooding the network to learn MAC addresses (ancient and inefficient), EVPN distributes that information through BGP. VTEPs—the tunnel endpoints doing the encapsulation—know exactly where to send packets without the discovery overhead.

VXLAN security depends entirely on your VTEPs staying secure. Compromise a VTEP—physical switch or virtual—and isolation crumbles. Within a VXLAN segment, old attacks still work. ARP spoofing? Still effective between VMs of the same tenant. But jumping between VNIs? Nearly impossible. The VNI sits in the encapsulation header where tenants can't reach it.

3.3. Synthesis: Robustness, Scalability, and Vulnerabilities in Multi-Tenant Isolation
InfiniBand wins on raw performance. Silicon-enforced P_Keys beat software VTEPs for speed and certainty. No question.

Ethernet wins on scale and flexibility. 16 million possible segments versus InfiniBand's thousands. Segments that span data centers, cross oceans, integrate with existing infrastructure. InfiniBand can't touch that operational flexibility.

But here's what really matters: metadata versus traffic isolation.

InfiniBand stops traffic cold but broadcasts everyone's address to the world. Tenants can't touch each other's data, but they can map your entire infrastructure. That violates every principle of multi-tenant security.

VXLAN flips this completely. Tenants see nothing outside their bubble—no topology, no neighbors, no hints about what else exists. Perfect metadata isolation. But now you're trusting software VTEPs. One compromised endpoint could inject traffic anywhere.

For sovereign AI, metadata isolation trumps everything else. Why? Because reconnaissance enables attacks. An attacker who can't see targets can't plan attacks. They can't identify high-value systems, can't map dependencies, can't find weak points.

VXLAN's complete blindness between tenants aligns with modern security thinking. Yes, you're trusting VTEPs. But you're preventing the reconnaissance that makes targeted attacks possible. That trade-off makes sense for nation-state threat models.

Section 4: Quality of Service (QoS) as an Attack Vector
QoS keeps your fabric running smoothly until someone weaponizes it. Then those same mechanisms that prevent congestion become tools for creating it.

InfiniBand and Ethernet fail differently under QoS attacks. One degrades gracefully. The other can collapse catastrophically.

4.1. InfiniBand QoS Abuse: Manipulating Service Levels and Virtual Lanes for Resource Starvation
InfiniBand uses Service Levels and Virtual Lanes for QoS. Your HCA tags packets with a 4-bit SL. Switches map SLs to VLs—separate queues with their own buffers. A scheduler decides which VL transmits next, usually weighted round-robin.

Simple system. Easy to abuse.

Malicious tenant tags everything high-priority? They hog the best queues. Your SM's QoS policy better be tight, or that tenant starves everyone else. Latency spikes. Timeouts trigger. Performance tanks.

But the fabric stays up. That's key—InfiniBand degrades but doesn't die.

Your defense? The SM controls everything. Configure strict SL-to-VL mappings. Set arbiter weights carefully. Limit which SLs each tenant can use. The hardware enforces these rules—hosts can't override them.

Bonus: InfiniBand's credit-based flow control laughs at traditional DoS attacks. SYN floods? Dropped in hardware before the OS sees them.

4.2. Ethernet QoS Abuse: Exploiting CoS/PFC for Denial-of-Service and Congestion Attacks
Ethernet QoS uses CoS tags and DSCP values to sort traffic into queues. Standard stuff. But RoCEv2 needs PFC to work, and PFC is a ticking bomb.

PFC creates "lossless" Ethernet by sending pause frames when buffers fill. Switch running low on buffer space? It tells upstream switches to stop sending that priority class. Seems reasonable.

Until an attacker floods one priority class. Pause frames cascade backward through your network. Then things get ugly:

First, buffer exhaustion. Paused traffic eats buffer memory upstream. Run out of buffers? Everything stops, not just the attacked priority.

Worse: PFC deadlocks. In a Clos fabric, pause frames can create circular dependencies. Switch A pauses B, B pauses C, C pauses A. Nothing moves. Your fabric locks up completely. Not slow—frozen.

This isn't performance degradation. This is complete fabric failure.

Preventing it requires perfect configuration. PFC thresholds, ECN marking, QoS policies—get any of these wrong and you're vulnerable. Modern switches with Virtual Output Queueing help—they queue at ingress, avoiding the reactive PFC problem entirely. But most fabrics still rely on PFC.

Rate limiting helps. Traffic policing helps. But one misconfiguration and your "lossless" fabric becomes a liability.

Different fabrics, different failures. InfiniBand under QoS attack: unfair but functional. Some tenants suffer, but packets keep flowing. RoCEv2 under PFC attack: potential complete collapse.

For regulated workloads requiring predictable failure modes? InfiniBand's graceful degradation beats Ethernet's catastrophic potential every time. Your fabric might run slowly, but it runs.

Section 5: Telemetry Integrity: Ensuring Trustworthy Fabric Observability
Bad telemetry blinds you. Attackers who control what you see control what you know. They hide their tracks, create false alerts, make you chase ghosts while they work.

InfiniBand gives you integrated telemetry you must trust. Ethernet gives you open telemetry you must secure. Neither is perfect.

5.1. Securing InfiniBand Telemetry: Protecting the SM-Agent Channel and Verifying Hardware Counters
InfiniBand centralizes everything. SMAs on every device collect counters—bandwidth, errors, congestion. They report to the SM, you see it in UFM. Clean, integrated, comprehensive.

Traps provide real-time alerts. Link down? Protocol violation? The SM knows immediately. Great for visibility, if you trust the channel.

Problem: Is that telemetry trustworthy? SMAs talk to the SM over QP0. M_Keys protect configuration changes going out, but what about telemetry coming back? The specs stay vague. A compromised host might inject fake traps, manipulate counters, hide attack traffic behind false data.

Worse: kernel bypass means your security tools can't see any of this. The management plane operates in complete darkness to traditional monitoring. You're flying blind, trusting hardware you can't verify.

Protect the SM above all else—physical security, access controls, the works. Enable SMP firewalls on HCAs to stop hosts from sending management packets. Modern adapters add secure boot and hardware roots-of-trust, giving you something to anchor trust to.

But you're still trusting a black box. The vendor says it's secure. Can you verify that independently? Not really.

5.2. Securing Ethernet Telemetry: Integrity in a Diverse Ecosystem
Ethernet offers telemetry choice. NetFlow for traffic analysis. sFlow for sampling. Streaming telemetry for real-time data. Pick what works for your needs. Standards-based, vendor-neutral, completely open.

Flexibility comes with responsibility.

These protocols ship data unencrypted over UDP. Performance first, security later—or never. Anyone with network position can intercept, modify, or inject telemetry. Hide attack flows, create false positives, manipulate your entire view of the network. Default configurations are sitting ducks.

You must add security yourself. IPsec or TLS for transport—non-negotiable. Secure your switch management interfaces because compromised devices produce compromised data. Use wired connections where possible; at least they can't be intercepted from the parking lot.

More work? Yes. But you control every aspect. You can audit every component. That transparency might be worth the effort.

Two philosophies, two problems.

InfiniBand: Trust us, it's secure. You get comprehensive telemetry from a vertically integrated stack. But can you audit it? Can you verify the cryptographic protections? Can you prove to regulators that your telemetry hasn't been tampered with? Not without the vendor's help.

Ethernet: Secure it yourself. Everything's open, documented, verifiable. But default configs are insecure. You carry the burden of implementation, configuration, and maintenance. One mistake and your telemetry lies to you.

For sovereign deployments requiring auditable security? Ethernet's transparency wins, despite the work involved. You can prove your security posture because you built it. InfiniBand asks for faith where Ethernet demands effort.

Section 6: Implications for Sovereign AI and Regulated Environments
Sovereign AI isn't about speed. It's about control, compliance, and independence. Your fabric choice determines whether you own your infrastructure or rent it, whether you can audit your security or must accept promises.

HIPAA, PCI-DSS, and national security frameworks don't care about your benchmarks. They care about provable controls.

6.1. Meeting the Demands of Sovereign AI: Data Residency, Control Plane Sovereignty, and Verifiable Isolation
Sovereign AI means your nation controls its AI destiny. Your data stays within your borders. Your models follow your laws. Your infrastructure answers to your government, not foreign corporations.

The vendor problem defines everything else. NVIDIA owns InfiniBand after buying Mellanox. One company controls your entire AI infrastructure—hardware, software, security patches. They decide your upgrade cycle. They set your prices. Geopolitical tensions? Your AI infrastructure becomes a bargaining chip.

Ethernet spreads that risk. Cisco, Arista, Juniper, and others compete on open standards. Prices drop. Innovation accelerates. Most importantly: no single foreign entity controls your critical infrastructure. That's what sovereignty actually means.

Data residency means more than geography. Tenants can't just be prevented from accessing each other's data—they can't know each other exists.

Remember InfiniBand's metadata leakage? In a sovereign cloud, that's catastrophic. Foreign intelligence services mapping your defense contractors' infrastructure. Competitors discovering each other's AI cluster sizes. The reconnaissance value alone breaks sovereignty principles.

VXLAN's complete tenant blindness fits sovereign requirements perfectly. Each tenant operates in total isolation, unaware of the larger fabric. That's not just security; it's operational sovereignty.

Governments demand proof, not promises. Ethernet delivers that proof through transparency. Every protocol documented. Every packet format published. Your security teams can monitor with Wireshark, analyze with standard tools, audit without vendor assistance.

InfiniBand's proprietary control plane? Good luck explaining SMPs to auditors. Try proving your security posture when the vendor controls the only tools that understand the protocol. "Trust us" doesn't satisfy regulators or security clearance requirements.

6.2. Aligning with Regulated Workloads: A Compliance Mapping for HIPAA and PCI-DSS
HIPAA and PCI-DSS don't negotiate. Meet their requirements or face penalties. They demand specific controls: access restrictions, audit trails, encryption in transit, network segmentation.

How do our fabrics measure up?

Here's what auditors will check:

Regulatory Requirement	Framework	InfiniBand Implementation & Analysis	Ethernet (RoCEv2) Implementation & Analysis
Network Access Control	HIPAA/PCI-DSS	P_Keys for data plane authorization. M_Keys for management plane. SM_Keys for control plane. Centralized policy via SM. Analysis: Strong, hardware-enforced but relies on SM integrity.	802.1X for port-level device authentication. ACLs on L3 switches. Security Groups in VXLAN overlays. Analysis: Layered, distributed control. More complex but offers defense-in-depth.
Network Segmentation	PCI-DSS	Partitions (P_Keys) provide hardware-enforced L2 isolation. Analysis: Strong traffic isolation but weak metadata isolation (topology discovery).	VLANs (traditional) and VXLAN (modern, scalable) provide L2-over-L3 segmentation. Analysis: Excellent metadata isolation and scalability. Enforcement relies on VTEP integrity.
Transmission Security	HIPAA/PCI-DSS	No native, on-the-wire encryption in the standard. Relies on application-level encryption or specialized hardware. Analysis: A significant gap for data-in-transit protection at the fabric level.	MACsec provides strong, line-rate link-layer encryption. IPsec can be used to secure RoCEv2 traffic at the network layer, though with performance overhead. Analysis: Mature, standardized options available.
Audit Trails & Monitoring	HIPAA/PCI-DSS	Centralized logging and telemetry via UFM. Traps for fabric events. Analysis: Comprehensive but proprietary. Integrity relies on secure SM-agent channel. Opaque to host tools.	Diverse ecosystem: NetFlow/IPFIX, sFlow, Streaming Telemetry. Logs from switches/routers. Analysis: Open and flexible, but requires explicit security (e.g., IPsec for collectors) and integration effort.
Protect Against Vulnerabilities	PCI-DSS	Hardened transport implemented in hardware (less susceptible to software exploits). Centralized SM for consistent patching. Analysis: Reduced software attack surface but vendor-dependent for patches.	Relies on OS/firmware of switches and NICs. Diverse ecosystem requires diligent patch management across multiple vendors. Analysis: Larger attack surface but not dependent on a single vendor's security response.

Export to Sheets
Both fabrics can pass audit—with work. But Ethernet's controls map directly to compliance requirements. Auditors understand 802.1X. They recognize MACsec. They can verify ACLs.

InfiniBand's P_Keys and M_Keys? You'll spend hours explaining them. The lack of native encryption? That's a red flag requiring compensating controls. Possible, but harder.

Section 7: Strategic Recommendations and Conclusion
Your fabric choice locks you in for years. Choose wrong and you'll live with the consequences through multiple hardware generations. There's no universal answer—only trade-offs that align with your specific risks and requirements.

7.1. Hardening InfiniBand Fabrics for High-Assurance Deployments
If you're running InfiniBand, the SM is everything. Protect it like your root certificate authority because that's essentially what it is.

Physical security for the SM—locked room, cameras, the works. Dedicated management network with zero routing to production. Firewall everything. Log everything. Trust nothing.

Change default SM_Keys immediately. Generate strong ones. Configure allowed_sm_guids lists. No exceptions. Default keys are published knowledge—using them is negligence.

Define your topology statically. Every GUID, every port, every connection documented and enforced. New device appears? SM rejects it automatically. This stops both accidents and attacks.

Enable SMP firewalls everywhere. Block tenants from running ibnetdiscover. They don't need to see your fabric topology. If they complain, they're probably up to something.

InfiniBand doesn't encrypt on the wire. Accept this. Implement TLS everywhere. Application-layer encryption for sensitive data. Document these compensating controls for auditors because they will ask.

7.2. Architecting Secure and Resilient RoCEv2 Ethernet Fabrics
Ethernet demands expertise. You're building a house of cards that must withstand hurricanes. Every layer needs attention.

PFC will kill you if you let it. Over-provision buffers. Tune thresholds conservatively—better slow than deadlocked. Implement strict QoS policies. Police everything.

Better yet: choose VOQ-based switches. They queue at ingress, eliminating most PFC problems. More expensive? Yes. Worth it? When your fabric stays up during an attack, absolutely.

Zero trust or go home. 802.1X on every port—no device connects without authentication. MACsec on every link—assume attackers have physical access. Yes, it's complex. Yes, it adds latency. Do it anyway.

BGP sessions need authentication—MD5 at minimum, TCP-AO if supported. Control plane policing protects your switch CPUs from flooding. Without it, one misbehaving node can melt your entire control plane.

Telemetry lies unless you secure it. IPsec or TLS for every flow—sFlow, IPFIX, streaming telemetry, all of it. Unsecured telemetry is worse than no telemetry because it gives you false confidence.

7.3. A Risk-Based Framework for Fabric Selection in Sovereign and Regulated Contexts
Stop looking for the "secure" choice. Both fabrics can be secured. Both can be compromised. Your decision comes down to risk tolerance and capabilities.

For Sovereign AI: Ethernet wins on strategic grounds. Multiple vendors prevent foreign control. Open standards enable verification. VXLAN's metadata isolation keeps tenants truly separated—essential when those tenants might be defense contractors, intelligence agencies, or critical infrastructure providers.

Yes, it's harder to run. But sovereignty isn't about easy; it's about control.

For Regulated Workloads: It depends on your team. Ethernet's controls map perfectly to compliance frameworks—auditors love standards they recognize. But can you manage the complexity? Can you prevent PFC deadlocks? Do you have the expertise to tune ECN thresholds?

If not, InfiniBand's simpler operation might save you from yourself.

InfiniBand trades transparency for simplicity. Performance degrades predictably under attack. Management stays centralized. But you'll implement compensating controls for missing encryption. You'll explain metadata leakage to auditors. You'll depend on one vendor's security team.

Acceptable trade-offs? That's your call.

The bottom line: InfiniBand offers integrated simplicity at the cost of vendor lock-in and opacity. Ethernet offers flexibility and sovereignty at the cost of complexity and fragility.

Your choice shapes your security posture for the next decade. Look beyond benchmarks. Consider your threat model, your team's capabilities, your nation's strategic priorities.

Because in the end, the most secure fabric is the one you can actually secure.
